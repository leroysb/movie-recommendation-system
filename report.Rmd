---
title: "Harvard-Capstone-PH125.9-Leroy Buliro"
author: "Leroy Buliro"
date: "1/10/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. INTRODUCTION

In this project, we create a movie recommendation system using the MovieLens dataset which has 10 million observations. You can obtain the GroupLens Research data from [this link](http://files.grouplens.org/datasets/movielens/ml-10m.zip). Our main aim is to perform a data analysis and through visualization we shall find patterns to assist us in building a model that will provide an optimum movie recommendation to users.

The dataset is composed by 10000054 observations with:
- 69878 unique users
- 10677 movies

The key steps performed include:
1. Preparation of the work environment.
2. Preparation, exploration and visualizations of the data
3. Analysis of the obsertions.
4. Calculation of the optimal RMSE based on movieId, userId and month.

On following the above steps, our data model will reveal that the best predictors used to provide the optimum recommendation system are moveiId and UserId. The RMSE is _______.


## 2. METHODS AND ANALYSIS

### 2.1 Work Environment Preparation

We are going to use the following library:

```{r loading-libs, message=FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(rmarkdown)) install.packages("rmarkdown", repos = "http://cran.us.r-project.org")

```
  
Next we shall download the data

```{r}
dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)
```


### 2.2 Data Wrangling

We build the desired dataset using the code below.

```{r echo=FALSE, message=FALSE}
ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1)
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

#Add a year column generated from the timestamp column
dates <- as.Date(as.POSIXct(edx$timestamp, origin="1970-01-01"))
edx <- edx %>% mutate(year=year(dates))
```

We shall use the edx dataset onwards

### 2.3 Data Exploration and Visualizations

The data consists of: 
Total number of ratings
```{r echo=TRUE}
dim(edx)
```

Total number of movies
```{r echo=TRUE}
n_distinct(edx$movieId)
```

Total number of users
```{r echo=TRUE}
n_distinct(edx$userId)
```

And we can confirm that each user rated a movie using the following code
```{r eval=FALSE}
edx %>% filter(is.na(.$ratings))
```

The top 20 most viewed genres are
```{r echo=FALSE}
edx %>% separate_rows(genres, sep = "\\|") %>% group_by(genres) %>% summarize(count = n()) %>% top_n(20, count) %>% arrange(desc(count))
```

While the top 20 best rated movies are
```{r echo=FALSE}
edx %>% group_by(movieId) %>% summarize(title = title[1], count = n()) %>% top_n(20, count) %>%  arrange(desc(count))
```

Median number of ratings per year
```{r echo=FALSE}
# What year has the highest median number of ratings
edx %>% group_by(movieId) %>% summarize(n = n(), year = as.character(first(year))) %>%
  qplot(year, n, data = ., geom = "boxplot") +
  coord_trans(y = "sqrt") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
From the result, we can conclude that 1997 had the highest rating overall.

And the genre Drama/War with the highest overall ratings
```{r echo=FALSE}
# What year has the highest median number of ratings
edx %>% group_by(movieId) %>% summarize(n = n(), year = as.character(first(year))) %>%
  qplot(year, n, data = ., geom = "boxplot") +
  coord_trans(y = "sqrt") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


### 2.4 Data Analysis and Modelling

Let's look at some of the general properties of the data to better understand the challenge.
The first observation is that some users are more active than others at rating movies.
Notice that some users have rated over 1,000 movies while others have only rated a handful.
```{r echo=FALSE}
edx %>%
  dplyr::count(userId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() +
  ggtitle("Users")
```

The second thing we notice is that some movies get rated more than others. 
Here's the distribution. A normal distribution
```{r echo=FALSE}
edx %>% 
  dplyr::count(movieId) %>% 
  ggplot(aes(n)) + 
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() + 
  ggtitle("Movies")
```

From the two observations above, we can then prove that there's indeed a movie variability and a user variability. We'll use two predicts to model the data.

To compare different models or to see how well we're doing compared to some baseline, we need to quantify what it means to do well. We need a loss function, in this case the residual mean squared error since we can interpret it as similar to standard deviation. It is the typical error we make when predicting a movie rating. This will therefore be our modelling approach

We're going to predict the same rating for all movies, regardless of the user and movie. In this case, that's just the average of all the ratings. Using that, we'll get the first RMSE.

```{r eval=FALSE}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
  
mu_hat <- mean(train_set$rating)
mu_hat

naive_rmse <- RMSE(test_set$rating, mu_hat)
naive_rmse

predictions <- rep(2.5, nrow(test_set))
RMSE(test_set$rating, predictions)

# Because as we go along we will be comparing different approaches, we're going to create a table that's going to store the results that we obtain as we go along.

rmse_results <- data_frame(method = "Just the average", RMSE = naive_rmse)
```


### 2.5 LAMBDA and RMSE Calculations

Now let's see how much our prediction improves once we predict using the model that we just fit.

```{r}
mu <- mean(train_set$rating) 
movie_avgs <- train_set %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu))

movie_avgs %>% qplot(b_i, geom ="histogram", bins = 10, data = ., color = I("black"))

predicted_ratings <- mu + test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  .$b_i

model_1_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Movie Effect Model",
                                     RMSE = model_1_rmse ))
```

Our residual mean squared error did drop a little bit.
```{r echo=FALSE}
rmse_results %>% knitr::kable()
```

We continue to make it better.
```{r eval=FALSE}
train_set %>% 
  group_by(userId) %>% 
  summarize(b_u = mean(rating)) %>% 
  filter(n()>=100) %>%
  ggplot(aes(b_u)) + 
  geom_histogram(bins = 30, color = "black")

user_avgs <- test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

predicted_ratings <- test_set %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  .$pred

model_2_rmse <- RMSE(predicted_ratings, test_set$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Movie + User Effects Model",  
                                     RMSE = model_2_rmse ))
```


## 3. RESULT

We see that now we obtain a further improvement.
Our residual mean squared error dropped down to about 0.88, hence this is our optimal model.

```{r}
rmse_results %>% knitr::kable()
```

## 4. CONCLUSION
The spirit of the project was to predict movieratings from a long list of rated movies. Optimal RMSE of 0.8431355 is achieved.But throughout the analysis we have discovered patterns and trends beyond the project’s own objective. These found are: the subjective tendency of the user to select round numbers (3 and 5), the tendency to accumulate the highest number of ratings in movies of the 90’s period, as well as a higher score for older movies, but greater differentiation in the scores delivered on older movies. These interesting results could be the basis of a deeper analysis in the optimization for a more complete system.
